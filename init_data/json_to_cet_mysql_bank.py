#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CET å•è¯æ•°æ®å¯¼å…¥è„šæœ¬ï¼ˆé€šç”¨è¡¨ç»“æ„ç‰ˆï¼‰
è‡ªåŠ¨ä»æ–‡ä»¶åæå–ç±»åˆ«ï¼ˆå¦‚ cet4.json -> category=cet4ï¼‰
æ”¯æŒå­—æ®µï¼šåŸºç¡€å­—æ®µ + æ–°å¢å­—æ®µï¼ˆphone, star, picture, speech, realExamSentence, remMethodï¼‰
"""

import json
import os
import pymysql
from pymysql.err import OperationalError, ProgrammingError, IntegrityError
from typing import Dict, List, Any, Optional, Tuple

# -------------------------- ã€ä»…éœ€ä¿®æ”¹è¿™2å¤„é…ç½®ï¼ã€‘ --------------------------
# 1. MySQLè¿æ¥é…ç½®ï¼ˆå¡«ä½ çš„å®é™…ä¿¡æ¯ï¼‰
MYSQL_CONFIG = {
    "host": "127.0.0.1",
    "port": 3306,
    "user": "root",
    "password": "swx020708",  # âš ï¸ æ”¹æˆä½ çš„çœŸå®å¯†ç 
    "database": "word_origin",
    "charset": "utf8mb4"
}

# 2. JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆè‡ªåŠ¨ä»æ–‡ä»¶åæå–ç±»åˆ«ï¼Œå¦‚ cet4.json -> category=cet4ï¼‰
# æ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä¼šæå–è‡ªå·±çš„ç±»åˆ«åˆ†åˆ«å¯¼å…¥
JSON_FILE_PATHS = [
    r"D:\github\cet-word-api\data\CET4.json",
    r"D:\github\cet-word-api\data\CET6.json",
    r"D:\github\cet-word-api\data\KaoYan.json",
    # r"D:\data\è€ƒç ”.json",
    # r"D:\data\é›…æ€.json",
    # r"D:\data\é«˜ä¸­.json",
    # r"D:\data\åˆä¸­.json",
]

# -------------------------- æ— éœ€ä¿®æ”¹çš„æ ¸å¿ƒé€»è¾‘ --------------------------


def extract_category_from_filename(file_path: str) -> str:
    """
    ä»æ–‡ä»¶è·¯å¾„æå–ç±»åˆ«
    ä¾‹å¦‚ï¼šD:\data\CET4.json -> cet4
          D:\data\è€ƒç ”.json -> è€ƒç ”
          D:\data\CET-6_luan_1.json -> cet-6_luan_1
    """
    # è·å–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
    filename = os.path.basename(file_path)
    # å»æ‰æ‰©å±•å
    name_without_ext = os.path.splitext(filename)[0]
    # è½¬æ¢ä¸ºå°å†™ï¼ˆå¯é€‰ï¼Œå¦‚æœä½ å¸Œæœ›ç±»åˆ«ç»Ÿä¸€å°å†™ï¼‰
    # category = name_without_ext.lower()
    # æˆ–è€…ä¿æŒåŸæ ·
    category = name_without_ext
    
    print(f"ğŸ“ æ–‡ä»¶ï¼š{filename} -> ç±»åˆ«ï¼š{category}")
    return category


def replace_french_chars(text: Any) -> Any:
    """æ›¿æ¢æ³•è¯­ç‰¹æ®Šå­—æ¯ï¼Œé¿å…ä¹±ç /å…¥åº“å¤±è´¥"""
    if not text or not isinstance(text, str):
        return text
    
    replace_map = {
        'Ã©': 'e', 'Ã¨': 'e', 'Ãª': 'e', 'Ã«': 'e', 'Ã§': 'c',
        'Ã ': 'a', 'Ã¢': 'a', 'Ã´': 'o', 'Ã»': 'u', 'Ã¯': 'i',
        'Ã¼': 'u', 'Ã®': 'i', 'Ã¿': 'y'
    }
    for fr_char, en_char in replace_map.items():
        text = text.replace(fr_char, en_char)
    return text


def safe_get(data: Dict, key: str, default: Any = "") -> Any:
    """å®‰å…¨è·å–å­—å…¸å€¼ï¼Œå¤„ç†Noneå’Œéå­—å…¸æƒ…å†µ"""
    if not isinstance(data, dict):
        return default
    return data.get(key, default)


def safe_get_nested(data: Dict, *keys: str, default: Any = None) -> Any:
    """å®‰å…¨è·å–åµŒå¥—å­—å…¸å€¼ï¼Œä»»æ„å±‚çº§ä¸å­˜åœ¨æ—¶è¿”å›default"""
    current = data
    for key in keys:
        if not isinstance(current, dict):
            return default
        current = current.get(key, default)
        if current is None:
            return default
    return current


def parse_word_json(file_path: str, category: str) -> List[Dict]:
    """
    é€è¡Œè§£æJSON Linesæ ¼å¼çš„å•è¯æ–‡ä»¶
    å…¼å®¹æ–°æ—§JSONç»“æ„ï¼Œç¼ºå¤±å­—æ®µè‡ªåŠ¨å¡«å……é»˜è®¤å€¼
    """
    parsed_words = []
    line_num = 0
    
    try:
        with open(file_path, "r", encoding="utf8") as f:
            for line in f:
                line_num += 1
                line = line.strip()
                if not line:
                    continue
                
                try:
                    word = json.loads(line)
                    
                    # 1. åŸºç¡€å­—æ®µï¼ˆæ–°æ—§JSONéƒ½æœ‰ï¼‰
                    word_rank = safe_get(word, "wordRank", 0)
                    head_word = replace_french_chars(safe_get(word, "headWord", ""))
                    book_id = safe_get(word, "bookId", "")
                    
                    # 2. åµŒå¥—ç»“æ„è§£æï¼ˆå¸¦å®Œæ•´å®¹é”™ï¼‰
                    content = safe_get(word, "content", {})
                    word_detail = safe_get(content, "word", {})
                    word_inner_content = safe_get(word_detail, "content", {})
                    
                    # 3. ä¸»è¡¨åŸºç¡€å­—æ®µï¼ˆæ–°æ—§JSONéƒ½æœ‰ï¼‰
                    word_head = safe_get(word_detail, "wordHead", "")
                    word_id = safe_get(word_detail, "wordId", "")
                    us_phone = safe_get(word_inner_content, "usphone", "")
                    uk_phone = safe_get(word_inner_content, "ukphone", "")
                    us_speech = safe_get(word_inner_content, "usspeech", "")
                    uk_speech = safe_get(word_inner_content, "ukspeech", "")
                    
                    # 4. ã€æ–°å¢å­—æ®µã€‘å…¼å®¹å¤„ç†ï¼ˆæ–°JSONæœ‰ï¼Œæ—§JSONæ²¡æœ‰ï¼‰
                    phone = safe_get(word_inner_content, "phone", "")
                    star = safe_get(word_inner_content, "star", 0)
                    picture = safe_get(word_inner_content, "picture", "")
                    speech = safe_get(word_inner_content, "speech", "")
                    
                    # 5. å­è¡¨æ•°æ®è§£æï¼ˆå…¨éƒ¨ä½¿ç”¨å®‰å…¨è·å–ï¼‰
                    trans_list = safe_get(word_inner_content, "trans", [])
                    exam_list = safe_get(word_inner_content, "exam", [])
                    sentence_obj = safe_get(word_inner_content, "sentence", {})
                    syno_obj = safe_get(word_inner_content, "syno", {})
                    phrase_obj = safe_get(word_inner_content, "phrase", {})
                    rel_word_obj = safe_get(word_inner_content, "relWord", {})
                    
                    # 6. ã€æ–°å¢å­è¡¨ã€‘çœŸé¢˜ä¾‹å¥ï¼ˆæ–°JSONæœ‰ï¼Œæ—§JSONæ²¡æœ‰ï¼‰
                    real_exam_sentence_obj = safe_get(word_inner_content, "realExamSentence", {})
                    
                    # 7. ã€æ–°å¢å­è¡¨ã€‘è®°å¿†æ–¹æ³•ï¼ˆæ–°JSONæœ‰ï¼Œæ—§JSONæ²¡æœ‰ï¼‰
                    rem_method_obj = safe_get(word_inner_content, "remMethod", {})
                    
                    parsed_words.append({
                        'category': category,  # ä»æ–‡ä»¶åæå–çš„ç±»åˆ«
                        'word_rank': word_rank,
                        'head_word': head_word,
                        'book_id': book_id,
                        'word_head': word_head,
                        'word_id': word_id,
                        'us_phone': us_phone,
                        'uk_phone': uk_phone,
                        'us_speech': us_speech,
                        'uk_speech': uk_speech,
                        # æ–°å¢å­—æ®µ
                        'phone': phone,
                        'star': star if star else 0,
                        'picture': picture,
                        'speech': speech,
                        # å­è¡¨æ•°æ®
                        'trans': trans_list if isinstance(trans_list, list) else [],
                        'exams': exam_list if isinstance(exam_list, list) else [],
                        'sentence': sentence_obj if isinstance(sentence_obj, dict) else {},
                        'syno': syno_obj if isinstance(syno_obj, dict) else {},
                        'phrase': phrase_obj if isinstance(phrase_obj, dict) else {},
                        'rel_word': rel_word_obj if isinstance(rel_word_obj, dict) else {},
                        # æ–°å¢å­è¡¨
                        'real_exam_sentence': real_exam_sentence_obj if isinstance(real_exam_sentence_obj, dict) else {},
                        'rem_method': rem_method_obj if isinstance(rem_method_obj, dict) else {}
                    })
                    
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  ç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥ï¼š{str(e)}ï¼Œå·²è·³è¿‡")
                except Exception as e:
                    print(f"âš ï¸  ç¬¬{line_num}è¡Œæ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}ï¼Œå·²è·³è¿‡")
                    
        print(f"âœ…  æ–‡ä»¶è§£æå®Œæˆï¼š{file_path}ï¼Œå…±è§£æå‡º{len(parsed_words)}æ¡æœ‰æ•ˆå•è¯æ•°æ®")
        return parsed_words
        
    except FileNotFoundError:
        print(f"âŒ  æœªæ‰¾åˆ°JSONæ–‡ä»¶ï¼š{file_path}")
        return []
    except PermissionError:
        print(f"âŒ  æ— æƒé™è¯»å–JSONæ–‡ä»¶ï¼š{file_path}")
        return []
    except Exception as e:
        print(f"âŒ  æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{file_path}ï¼Œé”™è¯¯ï¼š{str(e)}")
        return []


def insert_word_to_mysql(conn, cursor, word_data: Dict) -> bool:
    """
    æ’å…¥å•ä¸ªå•è¯åŠå…¶æ‰€æœ‰å…³è”æ•°æ®åˆ°æ•°æ®åº“ï¼ˆé€šç”¨è¡¨ç»“æ„ï¼‰
    åŒ…å«å®Œæ•´çš„äº‹åŠ¡å¤„ç†å’Œé”™è¯¯å›æ»š
    """
    
    try:
        # ==================== 1. æ’å…¥ä¸»è¡¨ï¼ˆæ–°å¢categoryå­—æ®µï¼‰====================
        insert_main_sql = """
            INSERT INTO words (
                category, word_rank, head_word, book_id, word_head, word_id,
                us_phone, uk_phone, us_speech, uk_speech,
                phone, star, picture, speech
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                word_rank=VALUES(word_rank),
                word_head=VALUES(word_head),
                word_id=VALUES(word_id),
                us_phone=VALUES(us_phone),
                uk_phone=VALUES(uk_phone),
                us_speech=VALUES(us_speech),
                uk_speech=VALUES(uk_speech),
                phone=VALUES(phone),
                star=VALUES(star),
                picture=VALUES(picture),
                speech=VALUES(speech);
        """
        
        cursor.execute(insert_main_sql, (
            word_data['category'],  # æ–°å¢ï¼šç±»åˆ«å­—æ®µ
            word_data['word_rank'], 
            word_data['head_word'], 
            word_data['book_id'],
            word_data['word_head'], 
            word_data['word_id'],
            word_data['us_phone'], 
            word_data['uk_phone'],
            word_data['us_speech'], 
            word_data['uk_speech'],
            word_data['phone'], 
            word_data['star'], 
            word_data['picture'], 
            word_data['speech']
        ))
        
        # è·å–ä¸»è¡¨IDï¼ˆå¤„ç†æ’å…¥æˆ–æ›´æ–°æƒ…å†µï¼‰
        main_id = cursor.lastrowid
        if main_id == 0:
            # æ›´æ–°æ“ä½œï¼Œéœ€è¦æŸ¥è¯¢IDï¼ˆå¸¦ä¸Šcategoryæ¡ä»¶ç¡®ä¿å‡†ç¡®ï¼‰
            cursor.execute("""
                SELECT id FROM words 
                WHERE category = %s AND head_word = %s AND book_id = %s
            """, (word_data['category'], word_data['head_word'], word_data['book_id']))
            result = cursor.fetchone()
            if result:
                main_id = result[0]
            else:
                raise Exception("æ— æ³•è·å–ä¸»è¡¨ID")
        
        # ==================== 2. æ’å…¥ç¿»è¯‘è¡¨ ====================
        if word_data['trans']:
            insert_trans_sql = """
                INSERT INTO word_trans (
                    word_main_id, pos, tran_cn, tran_other, desc_cn, desc_other
                ) VALUES (%s, %s, %s, %s, %s, %s);
            """
            trans_values = []
            for trans in word_data['trans']:
                if not isinstance(trans, dict):
                    continue
                trans_values.append((
                    main_id,
                    safe_get(trans, "pos", ""),
                    safe_get(trans, "tranCn", ""),
                    safe_get(trans, "tranOther", ""),
                    safe_get(trans, "descCn", ""),
                    safe_get(trans, "descOther", "")
                ))
            if trans_values:
                cursor.executemany(insert_trans_sql, trans_values)
        
        # ==================== 3. æ’å…¥ä¾‹å¥è¡¨ ====================
        sentences = safe_get(word_data['sentence'], "sentences", [])
        if sentences:
            insert_sent_sql = """
                INSERT INTO word_sentences (
                    word_main_id, s_content, s_cn, sent_desc
                ) VALUES (%s, %s, %s, %s);
            """
            sent_values = []
            sent_desc = safe_get(word_data['sentence'], "desc", "ä¾‹å¥")
            for sent in sentences:
                if not isinstance(sent, dict):
                    continue
                sent_values.append((
                    main_id,
                    safe_get(sent, "sContent", ""),
                    safe_get(sent, "sCn", ""),
                    sent_desc
                ))
            if sent_values:
                cursor.executemany(insert_sent_sql, sent_values)
        
        # ==================== 4. æ’å…¥çœŸé¢˜ä¾‹å¥è¡¨ ====================
        real_exam_sentences = safe_get(word_data['real_exam_sentence'], "sentences", [])
        if real_exam_sentences:
            insert_real_exam_sql = """
                INSERT INTO word_real_exam_sentences (
                    word_main_id, s_content, paper, level, year, type, real_exam_desc
                ) VALUES (%s, %s, %s, %s, %s, %s, %s);
            """
            real_exam_values = []
            real_exam_desc = safe_get(word_data['real_exam_sentence'], "desc", "çœŸé¢˜ä¾‹å¥")
            
            for sent in real_exam_sentences:
                if not isinstance(sent, dict):
                    continue
                source_info = safe_get(sent, "sourceInfo", {})
                real_exam_values.append((
                    main_id,
                    safe_get(sent, "sContent", ""),
                    safe_get(source_info, "paper", ""),
                    safe_get(source_info, "level", ""),
                    safe_get(source_info, "year", ""),
                    safe_get(source_info, "type", ""),
                    real_exam_desc
                ))
            if real_exam_values:
                cursor.executemany(insert_real_exam_sql, real_exam_values)
        
        # ==================== 5. æ’å…¥çŸ­è¯­è¡¨ ====================
        phrases = safe_get(word_data['phrase'], "phrases", [])
        if phrases:
            insert_phrase_sql = """
                INSERT INTO word_phrases (
                    word_main_id, p_content, p_cn, phrase_desc
                ) VALUES (%s, %s, %s, %s);
            """
            phrase_values = []
            phrase_desc = safe_get(word_data['phrase'], "desc", "çŸ­è¯­")
            for phrase in phrases:
                if not isinstance(phrase, dict):
                    continue
                phrase_values.append((
                    main_id,
                    safe_get(phrase, "pContent", ""),
                    safe_get(phrase, "pCn", ""),
                    phrase_desc
                ))
            if phrase_values:
                cursor.executemany(insert_phrase_sql, phrase_values)
        
        # ==================== 6. æ’å…¥åŒè¿‘ä¹‰è¯è¡¨ ====================
        synos = safe_get(word_data['syno'], "synos", [])
        if synos:
            insert_syno_sql = """
                INSERT INTO word_synos (
                    word_main_id, pos, syno_tran, syno_word, syno_desc
                ) VALUES (%s, %s, %s, %s, %s);
            """
            syno_values = []
            syno_desc = safe_get(word_data['syno'], "desc", "åŒè¿‘")
            
            for syno in synos:
                if not isinstance(syno, dict):
                    continue
                pos = safe_get(syno, "pos", "")
                tran = safe_get(syno, "tran", "")
                hwds = safe_get(syno, "hwds", [])
                
                for hwd in hwds:
                    if isinstance(hwd, dict):
                        syno_values.append((
                            main_id, pos, tran, 
                            safe_get(hwd, "w", ""), 
                            syno_desc
                        ))
            if syno_values:
                cursor.executemany(insert_syno_sql, syno_values)
        
        # ==================== 7. æ’å…¥åŒæ ¹è¯è¡¨ ====================
        rels = safe_get(word_data['rel_word'], "rels", [])
        if rels:
            insert_root_sql = """
                INSERT INTO word_roots (
                    word_main_id, pos, root_word, root_tran, root_desc
                ) VALUES (%s, %s, %s, %s, %s);
            """
            root_values = []
            root_desc = safe_get(word_data['rel_word'], "desc", "åŒæ ¹")
            
            for rel in rels:
                if not isinstance(rel, dict):
                    continue
                pos = safe_get(rel, "pos", "")
                words = safe_get(rel, "words", [])
                
                for w in words:
                    if isinstance(w, dict):
                        root_values.append((
                            main_id, pos, 
                            safe_get(w, "hwd", ""), 
                            safe_get(w, "tran", ""), 
                            root_desc
                        ))
            if root_values:
                cursor.executemany(insert_root_sql, root_values)
        
        # ==================== 8. æ’å…¥è®°å¿†æ–¹æ³•è¡¨ ====================
        if word_data['rem_method']:
            insert_rem_sql = """
                INSERT INTO word_rem_methods (
                    word_main_id, val, `desc`
                ) VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    val=VALUES(val),
                    `desc`=VALUES(`desc`);
            """
            cursor.execute(insert_rem_sql, (
                main_id,
                safe_get(word_data['rem_method'], "val", ""),
                safe_get(word_data['rem_method'], "desc", "è®°å¿†")
            ))
        
        # ==================== 9. æ’å…¥æµ‹è¯•é¢˜åŠé€‰é¡¹ ====================
        exams = word_data['exams']
        if exams:
            insert_exam_sql = """
                INSERT INTO word_exams (
                    word_main_id, question, exam_type, right_index, answer_explain
                ) VALUES (%s, %s, %s, %s, %s);
            """
            insert_choice_sql = """
                INSERT INTO word_exam_choices (
                    exam_main_id, choice_index, choice_content
                ) VALUES (%s, %s, %s);
            """
            
            for exam in exams:
                if not isinstance(exam, dict):
                    continue
                    
                answer = safe_get(exam, "answer", {})
                cursor.execute(insert_exam_sql, (
                    main_id,
                    safe_get(exam, "question", ""),
                    safe_get(exam, "examType", 0),
                    safe_get(answer, "rightIndex", 0),
                    safe_get(answer, "explain", "")
                ))
                exam_id = cursor.lastrowid
                
                # æ’å…¥é€‰é¡¹
                choices = safe_get(exam, "choices", [])
                if choices and exam_id:
                    choice_values = []
                    for choice in choices:
                        if isinstance(choice, dict):
                            choice_values.append((
                                exam_id,
                                safe_get(choice, "choiceIndex", 0),
                                safe_get(choice, "choice", "")
                            ))
                    if choice_values:
                        cursor.executemany(insert_choice_sql, choice_values)
        
        return True
        
    except Exception as e:
        print(f"âŒ  æ’å…¥å•è¯ '{word_data.get('head_word', 'unknown')}' å¤±è´¥ï¼š{str(e)}")
        raise


def process_single_file(file_path: str, conn, cursor) -> Tuple[int, int]:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ï¼ˆæˆåŠŸæ•°ï¼Œå¤±è´¥æ•°ï¼‰
    """
    # ä»æ–‡ä»¶åæå–ç±»åˆ«
    category = extract_category_from_filename(file_path)
    
    # è§£æJSON
    words = parse_word_json(file_path, category)
    if not words:
        return 0, 0
    
    print(f"ğŸ“Š  ç±»åˆ«ã€{category}ã€‘å…± {len(words)} ä¸ªå•è¯å¾…å¯¼å…¥")
    
    success_count = 0
    fail_count = 0
    
    for idx, word in enumerate(words, 1):
        try:
            conn.begin()
            insert_word_to_mysql(conn, cursor, word)
            conn.commit()
            success_count += 1
            
            if idx % 100 == 0 or idx == len(words):
                print(f"â³  {category} è¿›åº¦ï¼š{idx}/{len(words)} ({success_count}æˆåŠŸ/{fail_count}å¤±è´¥)")
                
        except Exception as e:
            conn.rollback()
            fail_count += 1
            print(f"âš ï¸  {category} ç¬¬{idx}ä¸ªå•è¯ '{word.get('head_word', 'unknown')}' å¤„ç†å¤±è´¥ï¼š{str(e)}")
            continue
    
    print(f"âœ…  {category} å¯¼å…¥å®Œæˆï¼æ€»è®¡ï¼š{len(words)}ï¼ŒæˆåŠŸï¼š{success_count}ï¼Œå¤±è´¥ï¼š{fail_count}\n")
    return success_count, fail_count


def process_all_files():
    """å¤„ç†æ‰€æœ‰JSONæ–‡ä»¶"""
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡ä»¶
    total_success = 0
    total_fail = 0
    total_files = 0
    
    # è¿æ¥æ•°æ®åº“
    conn = None
    cursor = None
    
    try:
        conn = pymysql.connect(**MYSQL_CONFIG)
        cursor = conn.cursor()
        
        print(f"ğŸš€  å¼€å§‹å¯¼å…¥æ•°æ®åˆ°MySQLï¼Œå…± {len(JSON_FILE_PATHS)} ä¸ªæ–‡ä»¶\n")
        
        for file_path in JSON_FILE_PATHS:
            if not os.path.exists(file_path):
                print(f"âŒ  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ï¼š{file_path}")
                continue
            
            total_files += 1
            success, fail = process_single_file(file_path, conn, cursor)
            total_success += success
            total_fail += fail
        
        print("=" * 60)
        print(f"ğŸ‰  å…¨éƒ¨å¯¼å…¥å®Œæˆï¼")
        print(f"   å¤„ç†æ–‡ä»¶æ•°ï¼š{total_files}")
        print(f"   æ€»æˆåŠŸï¼š{total_success}")
        print(f"   æ€»å¤±è´¥ï¼š{total_fail}")
        print("=" * 60)
        
    except OperationalError as e:
        error_code = e.args[0] if len(e.args) > 0 else 'Unknown'
        error_msg = e.args[1] if len(e.args) > 1 else str(e)
        print(f"âŒ  MySQLè¿æ¥å¤±è´¥ - é”™è¯¯ç ï¼š{error_code}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{error_msg}")
    except ProgrammingError as e:
        print(f"âŒ  SQLæ‰§è¡Œå¤±è´¥ï¼š{str(e)}ï¼Œè¯·æ£€æŸ¥è¡¨ç»“æ„æ˜¯å¦å­˜åœ¨")
    except Exception as e:
        print(f"âŒ  æ•°æ®å…¥åº“å¤±è´¥ï¼š{str(e)}")
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()
        print("ğŸ”š  MySQLè¿æ¥å·²å…³é—­")


# -------------------------- ä¸»æ‰§è¡Œå…¥å£ --------------------------
if __name__ == "__main__":
    print("=" * 60)
    print("CET å•è¯æ•°æ®å¯¼å…¥å·¥å…·ï¼ˆé€šç”¨è¡¨ç»“æ„ç‰ˆï¼‰")
    print("è‡ªåŠ¨ä»æ–‡ä»¶åæå–ç±»åˆ«")
    print("=" * 60)
    process_all_files()